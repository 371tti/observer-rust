# Joy-ConとWebカメラによるフルトラッキングソフト仕様

## 1. 概要
Joy-Con（左右２つ）と単眼Webカメラを組み合わせ、手足と体幹の位置・姿勢を推定・可視化するソフトウェア。ゲームエンジンや配信ソフトと連携し、VTuberやVRMアバターに活用可能。

## 2. 要件定義
- 入力デバイス
  - Nintendo Switch Joy-Con ×2（Bluetooth接続）
  - 標準的な解像度のWebカメラ（30fps以上）
- 出力形式
  - UnityやUnreal Engine向けWebSocket送信
  - VRM形式アバターのUnity拡張サンプル
- パフォーマンス
  - 全体遅延<50ms
  - CPU使用率<40%

## 3. 技術選定
| 機能             | ライブラリ／技術        | 理由                                       |
|-----------------|-------------------------|--------------------------------------------|
| Joy-Con接続     | `libjoycon` (C#)        | Windows/Mac/Linux対応のBluetoothライブラリ |
| カメラ姿勢推定   | MediaPipe Holistic      | ハンド・ボディ検出一体化、軽量           |
| 3Dモデリング    | Unity                   | 豊富なプラグイン、WebSocket対応           |
| ネットワーク     | WebSocket（SignalR）     | リアルタイム双方向通信                   |
| UI/設定画面      | Electron or Unity UI    | クロスプラットフォーム                   |

## 4. 処理フロー
1. 起動・初期化
   - Joy-Conペアリング
   - Webカメラ映像ストリーム開始
2. センサーデータ取得
   - Joy-Con傾き・加速度取得（100Hz）
   - カメラフレーム取得（30fps）
3. 姿勢推定
   - MediaPipeで2Dランドマーク検出
   - Joy-Conデータで3D相対角度補正
   - IKアルゴリズム（Inverse Kinematics）で骨格姿勢決定
4. データ合成・送信
   - Unity内部アバターに反映
   - WebSocket経由で外部アプリに送信
5. 描画・出力
   - Unity Sceneでアバター描画
   - OBS連携用仮想カメラ出力

## 5. 実装スケジュール（簡易）
| 期間    | タスク                              |
|--------|--------------------------------------|
| 1週目   | プロトタイプ（Joy-Con接続確認）      |
| 2週目   | MediaPipe組み込み、2D検出検証        |
| 3週目   | 3D姿勢推定・IKアルゴリズム実装       |
| 4週目   | Unity連携・WebSocket送信テスト      |
| 5週目   | UI実装・OBS連携動作確認            |

## 6. まとめ
Joy-ConとWebカメラを組み合わせたフルトラッキングは、手軽にコストを抑えたVR体験や配信ソリューションを実現。技術選定とフローを踏むことで、約1ヶ月でプロトタイプ構築可能。

---
*この記事は仕様策定と技術選定をまとめたものです。*